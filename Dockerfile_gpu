# Dockerfile.gpu
FROM nvidia/cuda:12.1.0-cudnn8-runtime-ubuntu22.04 as builder

# Install Python
RUN apt-get update && apt-get install -y --no-install-recommends \
    python3.10 \
    python3.10-venv \
    python3-pip \
    build-essential \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /build

COPY requirements-prod.txt .

# Create venv and install PyTorch with CUDA
RUN python3.10 -m venv /opt/venv
ENV PATH="/opt/venv/bin:$PATH"

RUN pip install --no-cache-dir --upgrade pip && \
    pip install --no-cache-dir torch==2.5.1 torchvision==0.20.1 --index-url https://download.pytorch.org/whl/cu121 && \
    pip install --no-cache-dir -r requirements-prod.txt

# Runtime stage
FROM nvidia/cuda:12.1.0-cudnn8-runtime-ubuntu22.04

ENV PYTHONUNBUFFERED=1 \
    PYTHONDONTWRITEBYTECODE=1 \
    PATH="/opt/venv/bin:$PATH" \
    CUDA_VISIBLE_DEVICES="0"

RUN apt-get update && apt-get install -y --no-install-recommends \
    python3.10 \
    libgomp1 \
    curl \
    && rm -rf /var/lib/apt/lists/*

RUN groupadd -r mlops && useradd -r -g mlops -u 1001 mlops

WORKDIR /app

COPY --from=builder /opt/venv /opt/venv
COPY --chown=mlops:mlops ./src /app/src
COPY --chown=mlops:mlops ./serve.py /app/
COPY --chown=mlops:mlops ./config /app/config

RUN mkdir -p /app/models /app/logs && chown -R mlops:mlops /app

USER mlops

EXPOSE 8000

HEALTHCHECK --interval=30s --timeout=10s --start-period=40s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

CMD ["uvicorn", "serve:app", "--host", "0.0.0.0", "--port", "8000", "--workers", "1"]